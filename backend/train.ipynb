{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import random\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from icecream import ic\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the directories for data\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'dataset')\n",
    "IMAGE_DIR = [os.path.join(os.path.join(os.getcwd(), 'dataset'), f'images_{str(i).zfill(3)}', 'images') for i in range(1, 13)]\n",
    "LABELS_CSV = os.path.join(DATA_DIR, 'Data_Entry_2017.csv')\n",
    "BBOX_CSV = os.path.join(DATA_DIR, 'BBox_List_2017.csv')\n",
    "\n",
    "labels = pd.read_csv(LABELS_CSV)\n",
    "bbox = pd.read_csv(BBOX_CSV)\n",
    "\n",
    "# Splitting the labels into multiple rows\n",
    "labels_expanded = labels.copy()\n",
    "labels_expanded['Finding Label'] = labels_expanded['Finding Labels'].str.split('|')\n",
    "\n",
    "# Making a unique Id column for each image\n",
    "labels_expanded['Id'] = list(zip(labels_expanded['Patient ID'], labels_expanded['Follow-up #']))\n",
    "labels_expanded = labels_expanded.explode('Finding Label')\n",
    "data = labels_expanded[['Id','Image Index', 'Finding Label', 'Patient Age', 'Patient Gender', 'View Position']].copy()\n",
    "\n",
    "# Adding the disease code to the data\n",
    "unique_diseases = data['Finding Label'].unique()\n",
    "disease_to_number = {disease: idx for idx, disease in enumerate(unique_diseases)}\n",
    "data.loc[:, 'Disease Code'] = data['Finding Label'].map(disease_to_number)\n",
    "data['Id'] = data.apply(lambda row: (row['Id'][0], row['Id'][1], row['Disease Code']), axis=1)\n",
    "data = data[['Id', 'Image Index', 'Finding Label', 'Patient Age', 'Patient Gender', 'View Position']]\n",
    "\n",
    "# Resetting the index\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "# img = data.iloc[3]\n",
    "# print(type(data.loc[1,'Id']))\n",
    "\n",
    "# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "# val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob.glob(os.path.join(DATA_DIR, 'images_*', 'images', '*.png'))\n",
    "image_dict = {os.path.basename(path): path for path in image_paths}\n",
    "\n",
    "sample_images = data['Image Index'].unique()\n",
    "img_name = np.random.choice(sample_images, size=1, replace=False)[0]\n",
    "img_path = image_dict.get(img_name)\n",
    "img = Image.open(img_path)\n",
    "data1 = data[data['Image Index'] == img_name]\n",
    "# print(img)\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.title(f\"Findings: {', '.join(data1['Finding Label'].unique())}\", fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "img = torchvision.io.decode_image(image_dict.get(\"00000001_000.png\"))\n",
    "# print(img.shape)\n",
    "img = img.permute(1,2,0)\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIH_dataset(Dataset):\n",
    "    '''\n",
    "    Custom dataset class for the NIH\\n\n",
    "    params:\\n\n",
    "    df: Pandas dataframe containing the data\\n\n",
    "    image_directories: list of directories in string containing the images\\n\n",
    "    transform: torchvision.transforms.transforms. DO NOT PASS transforms.to_tensor() here\\n\n",
    "    target_transform: Not used here\\n\n",
    "    '''\n",
    "    def __init__(self, df: pd.DataFrame, image_directories: list[str], transform: torchvision.transforms=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_directories\n",
    "        self.transform = transform\n",
    "        self.image_to_path = {os.path.basename(path): path for path in self.image_dir}\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path = self.image_to_path.get(self.df.loc[idx, 'Image Index'])\n",
    "        label: str = self.df.loc[idx, 'Finding Label']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label #returns img as tensor matrix, label as string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the parameters and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the image paths\n",
    "image_paths = glob.glob(os.path.join(DATA_DIR, 'images_*', 'images', '*.png'))\n",
    "\n",
    "# Setting the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 2048\n",
    "test_split_size = 0.001\n",
    "train_size = 0.0005\n",
    "# num_of_workers = 16\n",
    "\n",
    "# Defining the model, loss function and optimizer\n",
    "weights = models.ResNet50_Weights.DEFAULT # Pretrained weights\n",
    "model = models.resnet50(weights=weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, 15) # Change the output layer to 15 classes\n",
    "model = model.to(device) # Move the model to the device\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Try different transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(degrees=30),\n",
    "    # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "    # transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485], [0.229])\n",
    "    \n",
    "])\n",
    "\n",
    "#splitting the dataset\n",
    "train_df, test_df = train_test_split(data,test_size=test_split_size,train_size=train_size)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_dataset = NIH_dataset(df=train_df, image_directories=image_paths, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# image_to_path = {os.path.basename(path): path for path in IMAGE_DIR}\n",
    "# print(image_to_path.get(train_df.loc[85178, 'Image Index']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs: int, model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, criterion: torch.nn.Module, optimizer: torch.optim.Optimizer) -> torch.nn.Module:\n",
    "    losses, precisions, recalls, f1_scores, accuracies = [], [], [], [], []\n",
    "    true_negatives, false_positives, false_negatives, true_positives = [], [], [], []\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        for inputs, labels in tqdm.tqdm(dataloader, leave=False):\n",
    "            \n",
    "            # Move input and label tensors to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = torch.tensor([disease_to_number[label] for label in labels]).to(device)\n",
    "            \n",
    "            # Zero out the optimizer\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            logits, out_lab = torch.max(outputs, 1)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Calculate the accuracy\n",
    "            accuracy = accuracy_score(labels.cpu(), out_lab.cpu())\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "            # Calculate the precision\n",
    "            precision = precision_score(labels.cpu(), out_lab.cpu(), average='macro', zero_division=0)\n",
    "            precisions.append(precision)\n",
    "\n",
    "            # Calculate the recall\n",
    "            recall = recall_score(labels.cpu(), out_lab.cpu(), average='macro', zero_division=0)\n",
    "            recalls.append(recall)\n",
    "\n",
    "            # Calculate the f1 score\n",
    "            f1 = f1_score(labels.cpu(), out_lab.cpu(), average='macro', zero_division=0)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            # Confusion matrix\n",
    "            conf_matrices = multilabel_confusion_matrix(labels.cpu(), out_lab.cpu())\n",
    "            conf_matrix = conf_matrices.sum(axis=0)\n",
    "            tn, fp, fn, tp = conf_matrix.ravel()\n",
    "            true_negatives.append(tn)\n",
    "            true_positives.append(tp)\n",
    "            false_positives.append(fp)\n",
    "            false_negatives.append(fn)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f'{np.mean(recalls)=} ,{np.mean(precisions)=} , {np.mean(f1_scores)=} , {np.mean(accuracies)=}', sep='\\n')\n",
    "    \n",
    "    return model\n",
    "\n",
    "resnet_trained = train(epochs, model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(resnet_trained.state_dict(), f\"{model.__class__.__name__}_{epochs}_epochs_{learning_rate}_lr_{batch_size}_batch_size.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
